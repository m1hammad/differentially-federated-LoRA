Model                     ,Scenario              ,Accuracy ,Loss                      ,Precision           ,Recall  ,F1 Score            ,ROC-AUC             ,Training Time (s)
prajjwal1/bert-tiny       ,LoRA Only             , 0.77936 ,      0.46838070055007935 ,0.7850364595914554  ,0.77936 ,0.7782560001321395  ,0.8687260991999999  , 212.36613488197327
prajjwal1/bert-tiny       ,LoRA + Federated      , 0.49996 ,      0.7056343342971801  ,0.41665666546652264 ,0.49996 ,0.3333866453377695  ,0.4937695072        ,   8.79647183418274
prajjwal1/bert-tiny       ,LoRA + Federated + DP , 0.49036 ,      0.7020280527496338  ,0.38233774071745347 ,0.49036 ,0.3385442280166973  ,0.42491394239999997 ,   9.242775201797485
google/mobilebert-uncased ,LoRA Only             , 0.49952 ,      0.7521259045028686  ,0.4992599309860976  ,0.49952 ,0.4513165333519034  ,0.5349470752000001  ,2996.309038877487
google/mobilebert-uncased ,LoRA + Federated      , 0.5     , 522849.569               ,0.25                ,0.5     ,0.33333333333333326 ,0.5                 ,   9.953310012817383
google/mobilebert-uncased ,LoRA + Federated + DP , 0.5     ,2446366.44042             ,0.25                ,0.5     ,0.33333333333333326 ,0.5                 ,   9.304370403289795
distilbert-base-uncased   ,LoRA Only             , 0.91052 ,      0.22023213155537844 ,0.9117856617746022  ,0.91052 ,0.9104511908383183  ,0.9727087584        ,1507.1998972892761
distilbert-base-uncased   ,LoRA + Federated      , 0.50768 ,      0.693070595703125   ,0.5083915849186436  ,0.50768 ,0.49701708409181256 ,0.5048707104        ,   9.314620018005371
distilbert-base-uncased   ,LoRA + Federated + DP , 0.5     ,      0.7004553686904907  ,0.25                ,0.5     ,0.33333333333333326 ,0.45861493759999994 ,   9.240631580352783
roberta-base              ,LoRA Only             , 0.9498  ,      0.1341447435593605  ,0.9498449844984498  ,0.9498  ,0.949798744968624   ,0.9885610111999998  ,3140.123699426651
roberta-base              ,LoRA + Federated      , 0.5     ,      0.696607423915863   ,0.25                ,0.5     ,0.33333333333333326 ,0.5426876736        ,   9.113586902618408
roberta-base              ,LoRA + Federated + DP , 0.5     ,      0.6955953297615052  ,0.25                ,0.5     ,0.33333333333333326 ,0.4652474368        ,   8.970236539840698
